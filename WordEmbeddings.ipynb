{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/x4d60AIhSsjVGbFlmdw3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JzsJ4mE-0iK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "def find_closest_word_embedding(word, embeddings_index):\n",
        "# find closest word embedding to any given word, where word is word that is being analyzed\n",
        "#and embeddings index is dictionary for word\n",
        "    word_embedding = embeddings_index.get(word)\n",
        "    if word_embedding is None:\n",
        "        return None, None\n",
        "    closest_word = None\n",
        "    highest_similarity = -1  # Initialize with the lowest possible cosine similarity\n",
        "    for key, value in embeddings_index.items():\n",
        "        if key == word:\n",
        "            continue\n",
        "        similarity = np.dot(word_embedding, value) / (np.linalg.norm(word_embedding) * np.linalg.norm(value))\n",
        "        if similarity > highest_similarity:\n",
        "            highest_similarity = similarity\n",
        "            closest_word = key\n",
        "    return closest_word, highest_similarity\n",
        "\n",
        "#pls change path for your own needs!\n",
        "glove_input_file = '/kaggle/input/glove6b300dtxt/glove.6B.300d.txt'\n",
        "\n",
        "# Load GloVe embeddings\n",
        "embeddings_index = load_glove_embeddings(glove_input_file)\n",
        "\n",
        "\n",
        "input_word = input(\"Enter a word: \").strip().lower()\n",
        "\n",
        "\n",
        "closest_word, highest_similarity = find_closest_word_embedding(input_word, embeddings_index)\n",
        "\n",
        "# Print output\n",
        "if closest_word is not None:\n",
        "    print(f\"Closest word to '{input_word}': {closest_word}\")\n",
        "    print(f\"Cosine similarity: {highest_similarity}\")\n",
        "else:\n",
        "    print(f\"No word embedding found for '{input_word}'\")"
      ],
      "metadata": {
        "id": "VWWX1Etv-2cG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}